{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b905323c",
   "metadata": {},
   "source": [
    "# 0. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f83a6247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout, GRU\n",
    "from tensorflow.keras.losses import cosine_similarity\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c13729a",
   "metadata": {},
   "source": [
    "# 1. Data and Model Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911f7250",
   "metadata": {},
   "source": [
    "## 1-1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e416b0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fpath = './data/Headline_Trainingdata.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "495d15b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total data: 1142\n",
      "\n",
      "Data examples:\n",
      "[{'company': 'Morrisons',\n",
      "  'id': 2,\n",
      "  'sentiment': 0.43,\n",
      "  'title': 'Morrisons book second consecutive quarter of sales growth'},\n",
      " {'company': 'IMI',\n",
      "  'id': 3,\n",
      "  'sentiment': -0.344,\n",
      "  'title': 'IMI posts drop in first-quarter organic revenue; warns on full '\n",
      "           'year'}]\n"
     ]
    }
   ],
   "source": [
    "with open(data_fpath, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print('Number of total data: %d\\n' % len(data))\n",
    "print('Data examples:')\n",
    "pprint(data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "019461ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "companies = []\n",
    "titles = []\n",
    "sentiments = []\n",
    "for i in range(len(data)):\n",
    "    ids.append(data[i]['id'])\n",
    "    companies.append(data[i]['company'])\n",
    "    titles.append(data[i]['title'])\n",
    "    sentiments.append(data[i]['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e587a07",
   "metadata": {},
   "source": [
    "## 1-2. BERT Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2241cf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cefc87",
   "metadata": {},
   "source": [
    "## 1-3. Vectorization to Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83fa9e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_titles = tokenizer(titles, padding=True, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77d7c5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7min 31s\n",
      "Wall time: 41.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = model(encoded_titles).last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f3ea01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tf.convert_to_tensor(sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da1e332",
   "metadata": {},
   "source": [
    "## 1-4. Train-test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77510666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1027\n",
      "Number of test samples: 115\n"
     ]
    }
   ],
   "source": [
    "train_idx, test_idx = train_test_split(range(len(ids)), test_size=0.1, random_state=1)\n",
    "X_train = tf.gather(X, train_idx)\n",
    "Y_train = tf.gather(Y, train_idx)\n",
    "X_test = tf.gather(X, test_idx)\n",
    "Y_test = tf.gather(Y, test_idx)\n",
    "print('Number of training samples: %d' % len(train_idx))\n",
    "print('Number of test samples: %d' % len(test_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404fd4b0",
   "metadata": {},
   "source": [
    "# 2. Train Sentiment Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6419415d",
   "metadata": {},
   "source": [
    "## 2-1. Build Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7641d0a",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "db9c2d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_hidden_size = 256\n",
    "dense_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2aa8e1",
   "metadata": {},
   "source": [
    "### Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "92774f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_8 (Bidirectio  (None, 29, 512)          1575936   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " biLSTM_layer_2 (Bidirection  (None, 512)              1182720   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense_layer_1 (Dense)       (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_layer_1 (Dropout)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_layer_2 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_layer_2 (Dropout)   (None, 128)               0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,923,009\n",
      "Trainable params: 2,923,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sentiment_model = keras.Sequential()\n",
    "sentiment_model.add(keras.Input(shape=(X.shape[1], X.shape[2])))\n",
    "sentiment_model.add(Bidirectional(GRU(lstm_hidden_size, return_sequences=True,\n",
    "                                      name='biLSTM_layer_1')))\n",
    "sentiment_model.add(Bidirectional(GRU(lstm_hidden_size), name='biLSTM_layer_2'))\n",
    "sentiment_model.add(Dense(dense_size*2, activation='gelu', name='dense_layer_1'))\n",
    "sentiment_model.add(Dropout(0.2, name='dropout_layer_1'))\n",
    "sentiment_model.add(Dense(dense_size, activation='gelu', name='dense_layer_2'))\n",
    "sentiment_model.add(Dropout(0.2, name='dropout_layer_2'))\n",
    "sentiment_model.add(Dense(1, activation='tanh', name='output_layer'))\n",
    "print(sentiment_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1a303d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = '20220602_bert_sentiment'\n",
    "batch_size = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9e9d5b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the epoch in the file name (uses `str.format`)\n",
    "checkpoint_path = exp_name + '/cp-{epoch:04d}.ckpt'\n",
    "\n",
    "# Create a callback that saves the model's weights every 10 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1,\n",
    "                                                 save_freq=10)\n",
    "\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "sentiment_model.save_weights(checkpoint_path.format(epoch=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f3c32e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일 (regression)\n",
    "sentiment_model.compile(loss='cosine_similarity',\n",
    "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=['cosine_similarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c029f5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 18s 18s/step - loss: 0.0011 - cosine_similarity: -0.0011 - val_loss: 0.1913 - val_cosine_similarity: -0.1913\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0143 - cosine_similarity: -0.0143 - val_loss: 0.1913 - val_cosine_similarity: -0.1913\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0559 - cosine_similarity: -0.0559 - val_loss: 0.1913 - val_cosine_similarity: -0.1913\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0406 - cosine_similarity: -0.0406 - val_loss: 0.1913 - val_cosine_similarity: -0.1913\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0537 - cosine_similarity: -0.0537 - val_loss: 0.1913 - val_cosine_similarity: -0.1913\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0406 - cosine_similarity: -0.0406 - val_loss: 0.1913 - val_cosine_similarity: -0.1913\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0471 - cosine_similarity: -0.0471 - val_loss: 0.1913 - val_cosine_similarity: -0.1913\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0274 - cosine_similarity: -0.0274 - val_loss: 0.1913 - val_cosine_similarity: -0.1913\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0647 - cosine_similarity: -0.0647 - val_loss: 0.1913 - val_cosine_similarity: -0.1913\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: saving model to 20220602_bert_sentiment\\cp-0010.ckpt\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0471 - cosine_similarity: -0.0471 - val_loss: 0.1913 - val_cosine_similarity: -0.1913\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: -0.0230 - cosine_similarity: 0.0230 - val_loss: 0.1913 - val_cosine_similarity: -0.1913\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0559 - cosine_similarity: -0.0559 - val_loss: 0.1913 - val_cosine_similarity: -0.1913\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: -0.0077 - cosine_similarity: 0.0077 - val_loss: 0.1913 - val_cosine_similarity: -0.1913\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0340 - cosine_similarity: -0.0340 - val_loss: 0.1913 - val_cosine_similarity: -0.1913\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0559 - cosine_similarity: -0.0559 - val_loss: 0.1913 - val_cosine_similarity: -0.1913\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0713 - cosine_similarity: -0.0713 - val_loss: 0.1913 - val_cosine_similarity: -0.1913\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0099 - cosine_similarity: -0.0099 - val_loss: 0.1913 - val_cosine_similarity: -0.1913\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.0099 - cosine_similarity: -0.0099 - val_loss: 0.1913 - val_cosine_similarity: -0.1913\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [120]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43msentiment_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcp_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\cl2022\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cl2022\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\.conda\\envs\\cl2022\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cl2022\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cl2022\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\.conda\\envs\\cl2022\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\cl2022\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\cl2022\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cl2022\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = sentiment_model.fit(X_train, Y_train, epochs=100, batch_size=batch_size,\n",
    "                              validation_split=1/9,\n",
    "                              verbose=1, workers=15, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d111690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result_fpath = exp_name + '.xlsx'\n",
    "df_result = pd.DataFrame({'train_sim': history.history['cosine_similarity'],\n",
    "                          'val_sim': history.history['val_cosine_similarity']})\n",
    "df_result.to_excel(train_result_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "62ed9448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 201ms/step\n",
      "Cosine similarity on test data:-0.0127\n"
     ]
    }
   ],
   "source": [
    "Y_pred = sentiment_model.predict(X_test)\n",
    "Y_pred = np.squeeze(Y_pred)\n",
    "print('Cosine similarity on test data:%.4f' % -cosine_similarity(Y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0c4549f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0307282 ,  0.02860223, -0.13742292, -0.10137612, -0.02497484,\n",
       "        0.06693387, -0.04862431, -0.10901194,  0.13828076, -0.04018787,\n",
       "        0.01311471,  0.06325718, -0.03880176, -0.05301975, -0.01960249,\n",
       "        0.01865119,  0.00034039, -0.09637383, -0.03594363,  0.01330043,\n",
       "       -0.02939804,  0.05623235, -0.01551616, -0.03550649, -0.0226656 ,\n",
       "       -0.06662359, -0.13722637, -0.08618344,  0.04916712, -0.10312538,\n",
       "       -0.08794115, -0.10029439,  0.06917384,  0.00213898,  0.02408555,\n",
       "       -0.00347129, -0.10474423, -0.08512443,  0.03649005, -0.03842682,\n",
       "       -0.01176735, -0.0976997 , -0.03193242, -0.08837546, -0.04835438,\n",
       "        0.04428313, -0.03356117,  0.01020439, -0.08735496,  0.04369081,\n",
       "        0.04899858,  0.00723328, -0.07913991,  0.07980208, -0.04276426,\n",
       "        0.02854053,  0.013426  , -0.03813474,  0.00470224, -0.07979129,\n",
       "       -0.01195675,  0.07811739, -0.10505171, -0.08434291, -0.07715809,\n",
       "       -0.07640834, -0.09716013,  0.0534755 , -0.08502798,  0.01969082,\n",
       "       -0.08691569,  0.0225707 , -0.06341453, -0.02551547,  0.07151675,\n",
       "       -0.03802803, -0.06170832, -0.02352737, -0.06070366, -0.06957813,\n",
       "        0.09609573, -0.04767886,  0.01350728,  0.01204927,  0.0348328 ,\n",
       "        0.08200223, -0.13443935, -0.08947042,  0.07061311,  0.03905897,\n",
       "       -0.06464463, -0.05822189, -0.08579125, -0.14721383,  0.05763566,\n",
       "       -0.00464558, -0.07035509, -0.03786082,  0.06190597, -0.02458931,\n",
       "        0.00055075, -0.04566095, -0.10011983, -0.1249458 ,  0.04857852,\n",
       "       -0.0963259 , -0.00183334,  0.02250382, -0.0796082 ,  0.01809713,\n",
       "        0.00078207,  0.07292172,  0.07235842,  0.01711298,  0.04568616],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
